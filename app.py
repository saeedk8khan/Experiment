# ======================================================================
# ðŸŸ© ADVANCED TIME SERIES ANALYZER â€“ Single-file Streamlit App (app.py)
# ======================================================================
# Paste this file as `app.py`. Requires the usual packages (see README or
# requirements.txt): streamlit, pandas, numpy, matplotlib, seaborn, plotly,
# statsmodels, openpyxl.
# Run locally: `streamlit run app.py`
# ======================================================================
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# ======================================================================
# ðŸŸ© BASIC CONFIGURATION
# ======================================================================
st.set_page_config(layout="wide", page_title="Advanced Time Series Analyzer")
st.title("ðŸ“Š Advanced Time Series Analysis & Visualization")

# ======================================================================
# ðŸŸ© SECTION 1: DATA INPUT & PREPARATION
# ======================================================================
st.sidebar.header("1. Data Input")
use_sample = st.sidebar.checkbox("Use sample dataset (provided)", value=True)
uploaded_file = None
if not use_sample:
    uploaded_file = st.sidebar.file_uploader("Upload CSV or Excel file", type=["csv", "xlsx"])

if use_sample:
    # The sample CSV file should be in the same folder as app.py.
    # If you deployed to Streamlit Cloud, upload sample_time_series.csv to the repo.
    try:
        df = pd.read_csv("sample_time_series.csv", parse_dates=["date"])
    except Exception:
        # If sample isn't present, create a minimal fallback sample
        dates = pd.date_range(start="2023-01-01", periods=365)
        df = pd.DataFrame({
            "date": dates,
            "series_a": np.random.randn(len(dates)).cumsum() + 10,
            "series_b": np.random.randn(len(dates)).cumsum() + 20
        })
else:
    if uploaded_file is None:
        st.info("Please upload a CSV/Excel file or enable 'Use sample dataset' in the sidebar.")
        st.stop()
    try:
        if uploaded_file.name.endswith(".csv"):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)
    except Exception as e:
        st.error(f"Failed to read uploaded file: {e}")
        st.stop()

# ðŸŸ© DATETIME COLUMN DETECTION
st.sidebar.header("2. Datetime Settings")
possible_dt = [c for c in df.columns if "date" in c.lower() or np.issubdtype(df[c].dtype, np.datetime64)]
if possible_dt:
    dt_col = st.sidebar.selectbox("Select datetime column", options=possible_dt, index=0)
else:
    dt_col = st.sidebar.selectbox("Select datetime column", options=df.columns)
    try:
        df[dt_col] = pd.to_datetime(df[dt_col])
    except Exception:
        st.error("Could not parse the chosen datetime column. Ensure it contains ISO-like dates.")
        st.stop()

df[dt_col] = pd.to_datetime(df[dt_col])
df = df.sort_values(dt_col).reset_index(drop=True)
df.set_index(dt_col, inplace=True)

# ======================================================================
# ðŸŸ© SECTION 2: UI CUSTOMIZATION & FILTERS
# ======================================================================
st.sidebar.header("3. Visualization & Filters")
plot_backend = st.sidebar.selectbox("Plot engine", ["Plotly (interactive)", "Matplotlib (static)"])
theme = st.sidebar.selectbox("Theme/template", ["default", "plotly_white", "plotly_dark", "seaborn", "classic"])
bg_color = st.sidebar.color_picker("Background color", "#ffffff")
show_grid = st.sidebar.checkbox("Show grid lines", value=True)
line_width = st.sidebar.slider("Line width", min_value=1, max_value=6, value=2)
marker_size = st.sidebar.slider("Marker size (for plotly)", min_value=4, max_value=12, value=6)

numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
if not numeric_cols:
    st.error("No numeric columns detected. Upload a dataset with numeric time series columns.")
    st.stop()

# ðŸŸ© Numeric filter (optional)
st.sidebar.header("4. Numeric Filter (optional)")
filter_col = st.sidebar.selectbox("Filter rows by numeric column", options=[None] + numeric_cols, index=0)
if filter_col:
    minv, maxv = float(df[filter_col].min()), float(df[filter_col].max())
    lo, hi = st.sidebar.slider("Filter range", min_value=minv, max_value=maxv, value=(minv, maxv))
    df = df[(df[filter_col] >= lo) & (df[filter_col] <= hi)]

# ======================================================================
# ðŸŸ© SECTION X: UNIT ROOT TEST (ADF & PP) â€” FINAL STABLE VERSION
# ======================================================================

import io
import numpy as np
from statsmodels.tsa.stattools import adfuller
from arch.unitroot import PhillipsPerron

st.header("ðŸ” Unit Root Test (ADF & PP)")

# Variable selection
selected_vars = st.multiselect("Select Variable(s) for Unit Root Test", df.columns)
selected_lag = st.selectbox("Select Lag Order", list(range(0, 10)), index=0)

# Transformation choice
diff_option = st.radio(
    "Select Data Level:",
    ["Level (Original Data)", "First Difference"],
    horizontal=True
)

if st.button("Run Unit Root Tests"):
    try:
        results = []

        for col in selected_vars:
            series = df[col].dropna()

            # Apply differencing if needed
            if diff_option == "First Difference":
                series = series.diff().dropna()

            # ----- ADF TEST -----
            adf_result = adfuller(series, maxlag=selected_lag, autolag=None)
            adf_stat = round(adf_result[0], 4)
            adf_p = round(adf_result[1], 4)
            adf_usedlag = adf_result[2]
            adf_nobs = adf_result[3]
            adf_crit = adf_result[4]
            adf_icbest = adf_result[5] if len(adf_result) > 5 else np.nan

            results.append({
                "Variable": col,
                "Test": "ADF",
                "Level": "First Diff" if diff_option == "First Difference" else "Level",
                "Lag Used": adf_usedlag,
                "AIC": round(adf_icbest, 4) if not np.isnan(adf_icbest) else None,
                "Test Statistic": adf_stat,
                "p-Value": adf_p,
                "1% CV": round(adf_crit.get('1%'), 4),
                "5% CV": round(adf_crit.get('5%'), 4),
                "10% CV": round(adf_crit.get('10%'), 4)
            })

            # ----- PHILLIPSâ€“PERRON TEST -----
            pp_res = PhillipsPerron(series, lags=selected_lag)
            results.append({
                "Variable": col,
                "Test": "PP",
                "Level": "First Diff" if diff_option == "First Difference" else "Level",
                "Lag Used": selected_lag,
                "AIC": None,
                "Test Statistic": round(pp_res.stat, 4),
                "p-Value": round(pp_res.pvalue, 4),
                "1% CV": None,
                "5% CV": None,
                "10% CV": None
            })

        # Combine results
        results_df = pd.DataFrame(results)

        # Display
        st.subheader("ðŸ“Š Unit Root Test Results")
        st.dataframe(results_df, use_container_width=True)

        # Copy results
        st.markdown("#### ðŸ“‹ Copy Results")
        st.code(results_df.to_markdown(index=False), language="markdown")

        # Download Excel
        excel_buf = io.BytesIO()
        with pd.ExcelWriter(excel_buf, engine="openpyxl") as writer:
            results_df.to_excel(writer, index=False, sheet_name="UnitRootResults")

        st.download_button(
            label="ðŸ“¥ Download Unit Root Test Results (Excel)",
            data=excel_buf.getvalue(),
            file_name="unit_root_results.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

    except Exception as e:
        st.error(f"Error while running Unit Root Tests: {e}")


# ======================================================================
# ðŸŸ© SECTION X: COINTEGRATION ANALYSIS (ENGLEâ€“GRANGER & JOHANSEN)
# ======================================================================

import io
from statsmodels.tsa.stattools import coint
from statsmodels.tsa.vector_ar.vecm import coint_johansen

st.header("ðŸ”— Cointegration Analysis")

# Variable selection
st.subheader("Variable Selection")
selected_vars = st.multiselect("Select Variables for Cointegration Analysis", df.columns.tolist())

# Lag selection
selected_lag = st.selectbox("Select Maximum Lag", list(range(0, 10)), index=1)

# Test selection buttons
col_btn1, col_btn2 = st.columns(2)
run_engle = col_btn1.button("Run Engleâ€“Granger Cointegration Test")
run_johansen = col_btn2.button("Run Johansen Cointegration Test")

# ====================== ENGLEâ€“GRANGER TEST ======================
if run_engle:
    try:
        if len(selected_vars) < 2:
            st.warning("Please select at least two variables for Engleâ€“Granger test.")
        else:
            results = []
            y = selected_vars[0]
            x_vars = selected_vars[1:]

            for x in x_vars:
                score, pvalue, _ = coint(df[y].dropna(), df[x].dropna(), maxlag=selected_lag)
                results.append({
                    "Test Type": "Engleâ€“Granger",
                    "Dependent (Y)": y,
                    "Independent (X)": x,
                    "Lag Used": selected_lag,
                    "Test Statistic": round(score, 4),
                    "p-Value": round(pvalue, 4)
                })

            results_df = pd.DataFrame(results)

            st.subheader("ðŸ“Š Engleâ€“Granger Cointegration Test Results")
            st.dataframe(results_df, use_container_width=True)

            # Copy results
            st.markdown("#### ðŸ“‹ Copy Results")
            st.code(results_df.to_markdown(index=False), language="markdown")

            # Download results
            excel_buf = io.BytesIO()
            with pd.ExcelWriter(excel_buf, engine="openpyxl") as writer:
                results_df.to_excel(writer, index=False, sheet_name="EngleGranger")
            st.download_button(
                label="ðŸ“¥ Download Engleâ€“Granger Results (Excel)",
                data=excel_buf.getvalue(),
                file_name="engle_granger_results.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

    except Exception as e:
        st.error(f"Error while running Engleâ€“Granger test: {e}")

# ====================== JOHANSEN TEST ======================
if run_johansen:
    try:
        if len(selected_vars) < 2:
            st.warning("Please select at least two variables for Johansen test.")
        else:
            data = df[selected_vars].dropna()

            johansen_result = coint_johansen(data, det_order=0, k_ar_diff=selected_lag)
            trace_stats = johansen_result.lr1
            trace_crit = johansen_result.cvt
            maxeig_stats = johansen_result.lr2
            maxeig_crit = johansen_result.cvm

            results_trace = pd.DataFrame({
                "Test": ["Johansen Trace"] * len(trace_stats),
                "Rank": list(range(len(trace_stats))),
                "Test Statistic": trace_stats.round(4),
                "Crit 90%": trace_crit[:, 0].round(4),
                "Crit 95%": trace_crit[:, 1].round(4),
                "Crit 99%": trace_crit[:, 2].round(4)
            })

            results_maxeig = pd.DataFrame({
                "Test": ["Johansen Max-Eigen"] * len(maxeig_stats),
                "Rank": list(range(len(maxeig_stats))),
                "Test Statistic": maxeig_stats.round(4),
                "Crit 90%": maxeig_crit[:, 0].round(4),
                "Crit 95%": maxeig_crit[:, 1].round(4),
                "Crit 99%": maxeig_crit[:, 2].round(4)
            })

            results_df = pd.concat([results_trace, results_maxeig], ignore_index=True)

            st.subheader("ðŸ“Š Johansen Cointegration Test Results")
            st.dataframe(results_df, use_container_width=True)

            # Copy results
            st.markdown("#### ðŸ“‹ Copy Results")
            st.code(results_df.to_markdown(index=False), language="markdown")

            # Download results
            excel_buf = io.BytesIO()
            with pd.ExcelWriter(excel_buf, engine="openpyxl") as writer:
                results_df.to_excel(writer, index=False, sheet_name="Johansen")
            st.download_button(
                label="ðŸ“¥ Download Johansen Results (Excel)",
                data=excel_buf.getvalue(),
                file_name="johansen_results.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

    except Exception as e:
        st.error(f"Error while running Johansen test: {e}")


# ======================================================================
# ðŸŸ© SECTION 3: DESCRIPTIVE STATISTICS & DATA OVERVIEW (RAW / LOG OPTION)
# ======================================================================

import io
import numpy as np

st.header("ðŸ§¾ Descriptive Statistics & Data Overview")

# ðŸŸ© User selects whether to use raw or log-transformed data
data_option = st.radio(
    "Select data type for descriptive statistics:",
    ["Raw Data", "Log-Transformed Data"],
    horizontal=True
)

# ðŸŸ© Prepare data according to user selection
if data_option == "Log-Transformed Data":
    # Replace non-positive values with NaN to avoid log errors
    log_df = df.copy()
    for col in log_df.select_dtypes(include=[np.number]).columns:
        log_df[col] = log_df[col].apply(lambda x: np.log(x) if x > 0 else np.nan)
    display_df = log_df
else:
    display_df = df

col1, col2 = st.columns(2)

# ðŸŸ© Data Preview
with col1:
    st.subheader(f"{data_option} Preview")
    st.dataframe(display_df.head(50), use_container_width=True)

# ðŸŸ© Summary Statistics with 3 decimals
with col2:
    st.subheader(f"{data_option} Summary Statistics (Rounded to 3 Decimals)")
    summary_df = display_df.describe(include="all").round(3)
    st.dataframe(summary_df, use_container_width=True)

# ðŸŸ© Download descriptive stats as Excel
excel_buf = io.BytesIO()
with pd.ExcelWriter(excel_buf, engine="openpyxl") as writer:
    summary_df.to_excel(writer, index=True, sheet_name=f"{data_option}_Stats")

st.download_button(
    label=f"ðŸ“¥ Download {data_option} Summary Statistics (Excel)",
    data=excel_buf.getvalue(),
    file_name=f"{data_option.lower().replace(' ', '_')}_summary_statistics.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
)

# ======================================================================
# ðŸŸ© SECTION 4: DEPENDENT / INDEPENDENT VARIABLE SELECTION
# ======================================================================
st.header("ðŸ”Ž Variable Selection")
dep_var = st.selectbox("Dependent variable (Y)", options=numeric_cols, index=0)
indep_var = st.selectbox("Independent variable (X) â€” optional", options=[None] + numeric_cols, index=0)


# ======================================================================
# ðŸŸ© SECTION 5: TIME SERIES PLOT (Enhanced â€“ Single or All Variables)
# ======================================================================
st.header("ðŸ“ˆ Time Series Plot")

plot_mode = st.radio(
    "Select Plot Mode:",
    options=["Single Variable", "All Variables"],
    index=0,
    horizontal=True
)

if plot_backend.startswith("Plotly"):
    fig = go.Figure()

    if plot_mode == "Single Variable":
        # Plot only the selected dependent (and optional independent) variable
        fig.add_trace(go.Scatter(
            x=df.index, y=df[dep_var], mode="lines+markers",
            name=dep_var, line=dict(width=line_width), marker=dict(size=marker_size)
        ))
        if indep_var and indep_var != dep_var:
            fig.add_trace(go.Scatter(
                x=df.index, y=df[indep_var], mode="lines",
                name=indep_var, line=dict(width=line_width)
            ))

    else:
        # Plot all numeric variables together
        for col in numeric_cols:
            fig.add_trace(go.Scatter(
                x=df.index, y=df[col], mode="lines",
                name=col, line=dict(width=line_width)
            ))

    fig.update_layout(
        title="Time Series Plot" if plot_mode == "All Variables" else f"Time Series: {dep_var}",
        plot_bgcolor=bg_color,
        paper_bgcolor=bg_color,
        legend_title="Variables"
    )
    if not show_grid:
        fig.update_xaxes(showgrid=False)
        fig.update_yaxes(showgrid=False)
    st.plotly_chart(fig, use_container_width=True)

else:
    # Matplotlib backend
    if theme == "seaborn":
        sns.set()
    else:
        plt.style.use('classic' if theme == "classic" else 'default')

    fig, ax = plt.subplots(figsize=(12, 4))

    if plot_mode == "Single Variable":
        ax.plot(df.index, df[dep_var], linewidth=line_width, marker='o', markersize=marker_size/2, label=dep_var)
        if indep_var and indep_var != dep_var:
            ax.plot(df.index, df[indep_var], linewidth=line_width, alpha=0.8, label=indep_var)
    else:
        for col in numeric_cols:
            ax.plot(df.index, df[col], linewidth=line_width, label=col)

    ax.set_facecolor(bg_color)
    ax.grid(show_grid)
    ax.set_title("Time Series Plot" if plot_mode == "All Variables" else f"Time Series: {dep_var}")
    ax.legend(loc="upper right", fontsize="small")
    st.pyplot(fig)

# ======================================================================
# ðŸŸ© SECTION 7: SCATTER PLOT
# ======================================================================
st.header("ðŸ”¹ Scatter Plot")
sx = st.selectbox("Scatter X (independent)", options=numeric_cols, index=0, key="sx")
sy = st.selectbox("Scatter Y (dependent)", options=numeric_cols, index=min(1, len(numeric_cols)-1), key="sy")
color_by_options = [None] + [c for c in df.columns if df[c].nunique() < 50]
color_by = st.selectbox("Color by (categorical) â€” optional", options=color_by_options, index=0)
if plot_backend.startswith("Plotly"):
    scdf = df.reset_index()
    fig_s = px.scatter(scdf, x=sx, y=sy, color=color_by if color_by else None,
                       title=f"{sy} vs {sx}")
    fig_s.update_layout(plot_bgcolor=bg_color, paper_bgcolor=bg_color)
    st.plotly_chart(fig_s, use_container_width=True)
else:
    fig_s, axs = plt.subplots(figsize=(8, 5))
    axs.scatter(df[sx], df[sy], s=20)
    axs.set_facecolor(bg_color)
    axs.grid(show_grid)
    axs.set_title(f"{sy} vs {sx}")
    st.pyplot(fig_s)

# ======================================================================
# ======================================================================
# ðŸŸ© SECTION 8: CORRELATION HEATMAP (WITH COLOR PALETTE SELECTION)
# ======================================================================
st.header("ðŸ“‰ Correlation Heatmap")

# Sidebar color options for heatmap
st.sidebar.header("Heatmap Settings")
heatmap_palette = st.sidebar.selectbox(
    "Select heatmap color palette",
    ["coolwarm", "viridis", "plasma", "cividis", "magma", "crest", "rocket", "Spectral", "icefire", "vlag"],
    index=0
)

corr = df[numeric_cols].corr()
fig_c, axc = plt.subplots(figsize=(8, 6))
sns.heatmap(
    corr,
    annot=True,
    fmt=".2f",
    cmap=heatmap_palette,
    ax=axc,
    cbar_kws={"shrink": 0.8}
)
axc.set_facecolor(bg_color)
axc.set_title("Correlation Heatmap", fontsize=14, weight="bold")
st.pyplot(fig_c)

# ======================================================================
# ðŸŸ© SECTION 9: DISTRIBUTION COMPARISON (BAR, BOX, VIOLIN, STRIP)
# ======================================================================
import matplotlib.pyplot as plt
import seaborn as sns

st.header("ðŸ“Š Distribution Comparison")

# Select a numeric column
col_to_plot = st.selectbox("Select numeric variable for distribution analysis", numeric_cols, key="dist_col")

# Sidebar controls for background and style
st.sidebar.header("Distribution Chart Settings")
sns_style = st.sidebar.selectbox("Select Seaborn Style", ["whitegrid", "darkgrid", "white", "ticks", "dark"], index=1)
plt_style = st.sidebar.selectbox("Select Plot Style", ["default", "seaborn-v0_8-colorblind", "seaborn-v0_8-poster", "classic"], index=0)
sns.set_style(sns_style)
plt.style.use(plt_style)

# ðŸŸ© Function: create_distribution_chart
def create_distribution_chart(data_series, y_label, title):
    """
    Creates a figure with 4 horizontal subplots: bar, box, violin, strip.
    Each shows the same data in a different style.
    """
    fig, axes = plt.subplots(1, 4, figsize=(16, 5), sharey=True)
    
    # ðŸŸ© Subplot 1: Bar Plot (Mean & Std Dev)
    mean_val = data_series.mean()
    std_val = data_series.std()
    sns.barplot(x=["Mean"], y=[mean_val], ax=axes[0], color="skyblue", ci=None)
    axes[0].errorbar(x=[0], y=[mean_val], yerr=std_val, fmt='o', color='black', capsize=5)
    axes[0].set_xlabel("Mean & Std Dev")
    axes[0].set_ylabel(y_label)
    axes[0].set_title("Bar Plot")

    # ðŸŸ© Subplot 2: Box Plot
    sns.boxplot(y=data_series, ax=axes[1], color="lightgreen")
    axes[1].set_xlabel("Quartile Box")
    axes[1].set_title("Box Plot")

    # ðŸŸ© Subplot 3: Violin Plot
    sns.violinplot(y=data_series, ax=axes[2], color="lightcoral")
    axes[2].set_xlabel("Density")
    axes[2].set_title("Violin Plot")

    # ðŸŸ© Subplot 4: Strip Plot (with mean line)
    sns.stripplot(y=data_series, ax=axes[3], color="gray", jitter=True, alpha=0.6)
    axes[3].axhline(mean_val, color="red", linestyle="--", label=f"Mean = {mean_val:.2f}")
    axes[3].set_xlabel("Data Points")
    axes[3].set_title("Strip Plot")
    axes[3].legend(loc="upper right", fontsize="small")

    # ðŸŸ© Shared layout
    fig.suptitle(title, fontsize=16, weight="bold")
    fig.tight_layout(pad=2)
    return fig

# ðŸŸ© Generate and Display the Combined Distribution Plot
if col_to_plot:
    fig = create_distribution_chart(df[col_to_plot].dropna(), y_label=col_to_plot, title=f"Distribution Overview: {col_to_plot}")
    st.pyplot(fig)


# ======================================================================
# ðŸŸ© SECTION 10: DECOMPOSITION (TREND / SEASONAL / RESIDUAL)
# ======================================================================
st.header("ðŸ”¬ Seasonal Decomposition & Residuals")
period = st.number_input("Seasonal period (days)", min_value=2, max_value=2000, value=365)
try:
    decomp = seasonal_decompose(df[dep_var].dropna(), period=int(period), model='additive', extrapolate_trend='freq')
    # Plot decomposition with plotly for interactivity
    fig_d = go.Figure()
    fig_d.add_trace(go.Scatter(x=decomp.observed.index, y=decomp.observed, name="Observed"))
    fig_d.add_trace(go.Scatter(x=decomp.trend.index, y=decomp.trend, name="Trend"))
    fig_d.add_trace(go.Scatter(x=decomp.seasonal.index, y=decomp.seasonal, name="Seasonal"))
    fig_d.add_trace(go.Scatter(x=decomp.resid.index, y=decomp.resid, name="Residual"))
    fig_d.update_layout(title=f"Decomposition: {dep_var}", plot_bgcolor=bg_color, paper_bgcolor=bg_color)
    st.plotly_chart(fig_d, use_container_width=True)
except Exception as e:
    st.warning(f"Decomposition failed: {e}")

# ======================================================================
# ðŸŸ© SECTION 12: EXPORT / DOWNLOAD PROCESSED DATA
# ======================================================================
st.header("ðŸ’¾ Download Processed / Filtered Data")
to_download = df.reset_index()
csv_bytes = to_download.to_csv(index=False).encode('utf-8')
st.download_button("Download CSV of processed data", csv_bytes, file_name="processed_time_series.csv", mime="text/csv")


# ======================================================================
# ðŸŸ© SECTION 7: GRANGER CAUSALITY TEST (FINAL CLEAN VERSION)
# ======================================================================

import io
from statsmodels.tsa.stattools import grangercausalitytests

st.header("ðŸ” Granger Causality Test")

# ðŸŸ© User input selections
dependent_var = st.selectbox("Select Dependent Variable", df.columns)
independent_vars = st.multiselect("Select Independent Variable(s)", [c for c in df.columns if c != dependent_var])
max_lag = st.selectbox("Select Lag Order", list(range(1, 10)), index=0)

if st.button("Run Granger Causality Test"):
    try:
        results_list = []

        # Loop through selected independent variables
        for indep in independent_vars:
            temp_df = df[[dependent_var, indep]].dropna()

            # Run the Granger test for the selected lag only
            gc_res = grangercausalitytests(temp_df, maxlag=max_lag, verbose=False)
            f_test = gc_res[max_lag][0]['ssr_ftest'][0]
            p_value = gc_res[max_lag][0]['ssr_ftest'][1]
            results_list.append({
                "Hypothesis Tested": f"{indep} âžœ {dependent_var}",
                "Lag": max_lag,
                "F-test Statistic": round(f_test, 4),
                "Prob > F": round(p_value, 4)
            })

            # Reverse direction test (dependent âžœ independent)
            temp_df_rev = df[[indep, dependent_var]].dropna()
            gc_rev = grangercausalitytests(temp_df_rev, maxlag=max_lag, verbose=False)
            f_test_rev = gc_rev[max_lag][0]['ssr_ftest'][0]
            p_value_rev = gc_rev[max_lag][0]['ssr_ftest'][1]
            results_list.append({
                "Hypothesis Tested": f"{dependent_var} âžœ {indep}",
                "Lag": max_lag,
                "F-test Statistic": round(f_test_rev, 4),
                "Prob > F": round(p_value_rev, 4)
            })

        # ðŸŸ© Convert results to DataFrame
        gc_df = pd.DataFrame(results_list)

        st.subheader("ðŸ“Š Granger Causality Results")
        st.dataframe(gc_df, use_container_width=True)

        # ðŸŸ© Copy results
        st.markdown("#### ðŸ“‹ Copy Results")
        st.code(gc_df.to_markdown(index=False), language="markdown")

        # ðŸŸ© Download Excel
        excel_buf = io.BytesIO()
        with pd.ExcelWriter(excel_buf, engine="openpyxl") as writer:
            gc_df.to_excel(writer, index=False, sheet_name="GrangerResults")

        st.download_button(
            label="ðŸ“¥ Download Results (Excel)",
            data=excel_buf.getvalue(),
            file_name="granger_causality_results.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

    except Exception as e:
        st.error(f"Error while running Granger Causality Test: {e}")


# ======================================================================
# ðŸŸ© QUANTILE-on-QUANTILE REGRESSION (Unified Color Scheme)
# ======================================================================
st.header("ðŸ“ˆ Quantile-on-Quantile Regression (QQR)")

q_y = st.selectbox("Dependent variable (Y)", numeric_cols, index=0, key="qqr_y2")
q_x = st.selectbox("Independent variable (X)", [c for c in numeric_cols if c != q_y], index=0, key="qqr_x2")

potential_panels = [col for col in df.columns if col.lower() in ["country", "id", "entity", "firm", "region"]]
panel_col = potential_panels[0] if potential_panels else None
selected_groups = None
if panel_col:
    all_groups = df[panel_col].dropna().unique().tolist()
    selected_groups = st.multiselect(f"Select {panel_col}", all_groups, default=all_groups[:3])

quantile_n = st.slider("Number of Quantiles", 5, 30, 10, key="qqr_quantiles2")

if st.button("Run QQR", key="qqr_run2"):
    import numpy as np
    import plotly.graph_objects as go

    def run_qqr(y, x, title_suffix=""):
        data = pd.concat([y, x], axis=1).dropna()
        if data.empty or len(data) < 10:
            st.warning(f"âš ï¸ Insufficient observations for {title_suffix}")
            return

        y, x = data.iloc[:, 0], data.iloc[:, 1]
        qs = np.linspace(0.05, 0.95, quantile_n)
        z_matrix = np.full((len(qs), len(qs)), np.nan)

        for i, q1 in enumerate(qs):
            y_cut = y[y <= np.quantile(y, q1)]
            for j, q2 in enumerate(qs):
                x_cut = x[x <= np.quantile(x, q2)]
                common = min(len(y_cut), len(x_cut))
                if common > 3:
                    z_matrix[i, j] = np.corrcoef(y_cut.iloc[:common], x_cut.iloc[:common])[0, 1]

        z_matrix = np.nan_to_num(z_matrix, nan=0.0)

        # ---------- 2D Heatmap ----------
        fig_hm = go.Figure(
            go.Heatmap(
                z=z_matrix,
                x=[f"{q:.2f}" for q in qs],
                y=[f"{q:.2f}" for q in qs],
                colorscale="Viridis",
                colorbar_title="Correlation"
            )
        )
        fig_hm.update_layout(
            title=f"Quantile-on-Quantile Heatmap {title_suffix}",
            xaxis_title=f"{q_x} Quantiles",
            yaxis_title=f"{q_y} Quantiles",
            template="plotly_white",
            width=850,
            height=650
        )
        st.plotly_chart(fig_hm, use_container_width=True)

        # ---------- 3D Surface ----------
        fig_3d = go.Figure(data=[go.Surface(
            z=z_matrix,
            x=qs,
            y=qs,
            colorscale="Viridis",
            showscale=True,
            colorbar_title="Correlation"
        )])
        fig_3d.update_scenes(
            xaxis_title=f"{q_x} Quantiles",
            yaxis_title=f"{q_y} Quantiles",
            zaxis_title="Correlation"
        )
        fig_3d.update_layout(
            title=f"3D Surface QQR {title_suffix}",
            width=850,
            height=650,
            margin=dict(l=0, r=0, b=0, t=50),
            template="plotly_white"
        )
        st.plotly_chart(fig_3d, use_container_width=True)

    if panel_col and selected_groups:
        for grp in selected_groups:
            subset = df[df[panel_col] == grp]
            st.subheader(f"{panel_col}: {grp}")
            run_qqr(subset[q_y], subset[q_x], f"({grp})")
    else:
        run_qqr(df[q_y], df[q_x])


# ======================================================================
# ðŸŸ© SECTION 13: MACHINE LEARNING FORECASTING (PROPHET MODEL)
# ======================================================================
from prophet import Prophet

st.header("ðŸ¤– Machine Learning Forecasting (Prophet Model)")

# Select dependent and independent variables
dep_forecast = st.selectbox("Select dependent variable (target for forecasting)", numeric_cols, index=0, key="forecast_dep")
regressors = st.multiselect("Select independent variables (optional regressors)", [c for c in numeric_cols if c != dep_forecast])

# Select forecast horizon
periods = st.number_input("Forecast horizon (future days to predict)", min_value=7, max_value=1000, value=90)

if st.button("Run Forecast"):
    # Prepare data for Prophet
    df_prophet = df.reset_index()[[df.index.name, dep_forecast] + regressors].rename(columns={df.index.name: "ds", dep_forecast: "y"})

    # Initialize model
    model = Prophet(daily_seasonality=True, yearly_seasonality=True)
    for reg in regressors:
        model.add_regressor(reg)

    # Fit model
    try:
        model.fit(df_prophet)
        future = model.make_future_dataframe(periods=int(periods), freq="D")

        # Add regressors to future if available
        if regressors:
            last_vals = df_prophet[regressors].iloc[-1:].to_dict(orient="records")[0]
            for reg in regressors:
                future[reg] = last_vals[reg]

        forecast = model.predict(future)

        # Plot results
        st.subheader("Forecast Plot")
        fig_f = go.Figure()
        fig_f.add_trace(go.Scatter(x=df_prophet["ds"], y=df_prophet["y"], mode="lines", name="Observed"))
        fig_f.add_trace(go.Scatter(x=forecast["ds"], y=forecast["yhat"], mode="lines", name="Forecast"))
        fig_f.add_trace(go.Scatter(x=forecast["ds"], y=forecast["yhat_upper"], fill=None, mode="lines",
                                   line_color="lightgray", name="Upper Bound"))
        fig_f.add_trace(go.Scatter(x=forecast["ds"], y=forecast["yhat_lower"], fill='tonexty', mode="lines",
                                   line_color="lightgray", name="Lower Bound", opacity=0.3))
        fig_f.update_layout(title=f"Forecast for {dep_forecast} (Prophet Model)",
                            plot_bgcolor=bg_color, paper_bgcolor=bg_color)
        st.plotly_chart(fig_f, use_container_width=True)

        st.subheader("Forecast Components")
        st.pyplot(model.plot_components(forecast))

        st.subheader("Forecast Table (Last 30 predictions)")
        st.dataframe(forecast[["ds", "yhat", "yhat_lower", "yhat_upper"]].tail(30))

    except Exception as e:
        st.error(f"Forecasting failed: {e}")

# ======================================================================
# ðŸŸ© FOOTER & HELP
# ======================================================================
st.sidebar.header("Help & Run")
st.sidebar.markdown("Requirements: `streamlit pandas numpy matplotlib seaborn plotly statsmodels openpyxl`")
st.sidebar.markdown("Run locally: `streamlit run app.py`")
st.sidebar.markdown("Search for `# ðŸŸ© SECTION` to locate code blocks for editing.")

# End of file
